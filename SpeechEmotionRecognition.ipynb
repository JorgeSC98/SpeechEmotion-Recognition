{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JorgeSC98/SpeechEmotion-Recognition/blob/main/SpeechEmotionRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Emotion Recognition"
      ],
      "metadata": {
        "id": "5Rl9L8FOZMPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Authors\n",
        "Jorge Sáenz, Omar Muñoz, Elias Villalvazo, Israel Cárdenas, Luis Deutsch."
      ],
      "metadata": {
        "id": "MEIeUyJiZPZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "\n",
        "Speech Emotion Recognition (SER) is the act of attempting to recognize human\n",
        "emotion and affective states from speech, since voice often reflects different un-\n",
        "derlying emotions by the tone and pitch. This area of research encompasses an\n",
        "important problem that is receiving increasing interest due to its applications\n",
        "in areas such as audio surveillance, clinical studies, mental state recognition,\n",
        "conversational analysis, among others"
      ],
      "metadata": {
        "id": "FXXiMW-eZS1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "cIGPz48NZVMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction"
      ],
      "metadata": {
        "id": "FEikxIdKZXRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The raw audio files are processed, features are extracted and a database is created. Such steps are implemented in the related notebook below."
      ],
      "metadata": {
        "id": "fMSphKaPfjye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data extraction file"
      ],
      "metadata": {
        "id": "lGyN-fW6ex73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification models"
      ],
      "metadata": {
        "id": "KstiTX6cZf_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ory6WLHL_kEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9dfa2b8-ada7-43ec-92ce-633946102080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab            import files\n",
        "from google.colab            import drive\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network  import MLPClassifier\n",
        "from sklearn.preprocessing   import LabelEncoder\n",
        "from sklearn.preprocessing   import StandardScaler\n",
        "from sklearn.metrics         import accuracy_score\n",
        "from sklearn.metrics         import confusion_matrix, roc_curve, roc_auc_score, auc, ConfusionMatrixDisplay, mean_squared_error, classification_report\n",
        "from tqdm                    import tqdm\n",
        "from sklearn.svm             import SVC\n",
        "from sklearn                 import metrics\n",
        "from sklearn.datasets        import load_digits\n",
        "from matplotlib              import pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn                 import preprocessing\n",
        "\n",
        "from tensorflow.keras        import layers as L\n",
        "from tensorflow.keras        import layers\n",
        "from tensorflow.keras        import Model\n",
        "\n",
        "import matplotlib.pyplot     as plt\n",
        "import tensorflow            as tf\n",
        "import pandas                as pd\n",
        "import seaborn               as sns\n",
        "import numpy                 as np\n",
        "import os, glob, pickle\n",
        "import librosa\n",
        "import soundfile\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from file"
      ],
      "metadata": {
        "id": "elTFGoatWHqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_path     = '/content/gdrive/Myunit/Machine_Learning/SpeechRecognition/data/'\n",
        "filename    = 'database_4emotions.pkl'\n",
        "\n",
        "with open(db_path + filename, \"rb\") as fh:\n",
        "  df = pickle.load(fh)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "SLHje82cWKGj",
        "outputId": "394b91b4-e8f4-4dea-bdea-a81e745a71e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.119855  0.507461  0.414120  0.401716  0.409684  0.421298  0.516690   \n",
              "1  0.272872  0.598629  0.556412  0.565423  0.577642  0.594398  0.611372   \n",
              "2  0.113133  0.606384  0.411250  0.374669  0.412562  0.385073  0.455472   \n",
              "3  0.121266  0.480263  0.422342  0.468604  0.466126  0.490174  0.548692   \n",
              "4  0.253915  0.587318  0.601298  0.596231  0.615663  0.647406  0.576359   \n",
              "\n",
              "          7         8         9  ...           180           181        182  \\\n",
              "0  0.537631  0.590918  0.640058  ...  1.338648e-13  1.309344e-13  20.370474   \n",
              "1  0.538784  0.579985  0.654674  ...  9.955534e-05  1.028548e-04  14.896172   \n",
              "2  0.502469  0.521309  0.601805  ...  1.592488e-11  1.517740e-11  20.748005   \n",
              "3  0.555605  0.593634  0.596291  ...  5.084489e-12  5.084499e-12  21.361512   \n",
              "4  0.603092  0.619207  0.645742  ...  3.304043e-04  3.335241e-04  14.709076   \n",
              "\n",
              "         183        184        185        186        187        188   labels  \n",
              "0  18.402018  18.706955  17.229192  18.818294  18.757125  60.299300  fearful  \n",
              "1  17.230610  17.458664  15.637138  15.465091  14.857155  14.319924  fearful  \n",
              "2  18.602199  20.547905  18.824408  21.102303  20.811776  44.048627  fearful  \n",
              "3  19.764985  20.110708  17.858791  19.005673  19.560215  60.839976     calm  \n",
              "4  18.327844  18.166773  15.902382  15.985995  14.690535  13.897322     calm  \n",
              "\n",
              "[5 rows x 190 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d273efb-230b-4dd3-b488-f8ed0689f4af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.119855</td>\n",
              "      <td>0.507461</td>\n",
              "      <td>0.414120</td>\n",
              "      <td>0.401716</td>\n",
              "      <td>0.409684</td>\n",
              "      <td>0.421298</td>\n",
              "      <td>0.516690</td>\n",
              "      <td>0.537631</td>\n",
              "      <td>0.590918</td>\n",
              "      <td>0.640058</td>\n",
              "      <td>...</td>\n",
              "      <td>1.338648e-13</td>\n",
              "      <td>1.309344e-13</td>\n",
              "      <td>20.370474</td>\n",
              "      <td>18.402018</td>\n",
              "      <td>18.706955</td>\n",
              "      <td>17.229192</td>\n",
              "      <td>18.818294</td>\n",
              "      <td>18.757125</td>\n",
              "      <td>60.299300</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.272872</td>\n",
              "      <td>0.598629</td>\n",
              "      <td>0.556412</td>\n",
              "      <td>0.565423</td>\n",
              "      <td>0.577642</td>\n",
              "      <td>0.594398</td>\n",
              "      <td>0.611372</td>\n",
              "      <td>0.538784</td>\n",
              "      <td>0.579985</td>\n",
              "      <td>0.654674</td>\n",
              "      <td>...</td>\n",
              "      <td>9.955534e-05</td>\n",
              "      <td>1.028548e-04</td>\n",
              "      <td>14.896172</td>\n",
              "      <td>17.230610</td>\n",
              "      <td>17.458664</td>\n",
              "      <td>15.637138</td>\n",
              "      <td>15.465091</td>\n",
              "      <td>14.857155</td>\n",
              "      <td>14.319924</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.113133</td>\n",
              "      <td>0.606384</td>\n",
              "      <td>0.411250</td>\n",
              "      <td>0.374669</td>\n",
              "      <td>0.412562</td>\n",
              "      <td>0.385073</td>\n",
              "      <td>0.455472</td>\n",
              "      <td>0.502469</td>\n",
              "      <td>0.521309</td>\n",
              "      <td>0.601805</td>\n",
              "      <td>...</td>\n",
              "      <td>1.592488e-11</td>\n",
              "      <td>1.517740e-11</td>\n",
              "      <td>20.748005</td>\n",
              "      <td>18.602199</td>\n",
              "      <td>20.547905</td>\n",
              "      <td>18.824408</td>\n",
              "      <td>21.102303</td>\n",
              "      <td>20.811776</td>\n",
              "      <td>44.048627</td>\n",
              "      <td>fearful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.121266</td>\n",
              "      <td>0.480263</td>\n",
              "      <td>0.422342</td>\n",
              "      <td>0.468604</td>\n",
              "      <td>0.466126</td>\n",
              "      <td>0.490174</td>\n",
              "      <td>0.548692</td>\n",
              "      <td>0.555605</td>\n",
              "      <td>0.593634</td>\n",
              "      <td>0.596291</td>\n",
              "      <td>...</td>\n",
              "      <td>5.084489e-12</td>\n",
              "      <td>5.084499e-12</td>\n",
              "      <td>21.361512</td>\n",
              "      <td>19.764985</td>\n",
              "      <td>20.110708</td>\n",
              "      <td>17.858791</td>\n",
              "      <td>19.005673</td>\n",
              "      <td>19.560215</td>\n",
              "      <td>60.839976</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.253915</td>\n",
              "      <td>0.587318</td>\n",
              "      <td>0.601298</td>\n",
              "      <td>0.596231</td>\n",
              "      <td>0.615663</td>\n",
              "      <td>0.647406</td>\n",
              "      <td>0.576359</td>\n",
              "      <td>0.603092</td>\n",
              "      <td>0.619207</td>\n",
              "      <td>0.645742</td>\n",
              "      <td>...</td>\n",
              "      <td>3.304043e-04</td>\n",
              "      <td>3.335241e-04</td>\n",
              "      <td>14.709076</td>\n",
              "      <td>18.327844</td>\n",
              "      <td>18.166773</td>\n",
              "      <td>15.902382</td>\n",
              "      <td>15.985995</td>\n",
              "      <td>14.690535</td>\n",
              "      <td>13.897322</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 190 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d273efb-230b-4dd3-b488-f8ed0689f4af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d273efb-230b-4dd3-b488-f8ed0689f4af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d273efb-230b-4dd3-b488-f8ed0689f4af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[: ,:-1].values\n",
        "Y = df['labels'].values"
      ],
      "metadata": {
        "id": "ApC2xxm-WL8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale the feature vector"
      ],
      "metadata": {
        "id": "6OO5HJHqdYPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X      = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "oolsNFsqdatE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide in train and test"
      ],
      "metadata": {
        "id": "KlZS-dXNeAKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)"
      ],
      "metadata": {
        "id": "Il250dwDeF6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the class distribution"
      ],
      "metadata": {
        "id": "P8QdBgeHecZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMKs4GPNSUfV",
        "outputId": "9de4bbc0-7eea-41b5-a478-da1f58e30d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'calm': 428, 'disgust': 434, 'fearful': 437, 'happy': 429}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Count of Emotions', size=16)\n",
        "sns.countplot(y_train)\n",
        "plt.ylabel('Count', size=12)\n",
        "plt.xlabel('Emotions', size=12)\n",
        "sns.despine(top=True, right=True, left=False, bottom=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-UHSYCq9eeI9",
        "outputId": "303a956a-6557-40af-f169-0e04a812e433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change categorical variables to numerical"
      ],
      "metadata": {
        "id": "p9BoDtAgd66a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "integer_encoded      = label_encoder.fit_transform(y_train)\n",
        "integer_encoded_test = label_encoder.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "yU7-rIstd9uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_encoded = integer_encoded\n",
        "y_test_encoded = integer_encoded_test"
      ],
      "metadata": {
        "id": "EQz3paxoh9GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model\n",
        "\n",
        "The model below is extracted from: https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/\n",
        "\n",
        "This model is used as a baseline for comparing our own models."
      ],
      "metadata": {
        "id": "DIpunc8TZifk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model creation\n",
        "mlp_model = MLPClassifier(activation='relu', alpha=0.01,batch_size=256,beta_1=0.9,beta_2=0.999,early_stopping=False,epsilon=1e-08,hidden_layer_sizes=(300,), learning_rate='adaptive', learning_rate_init=0.001,\n",
        "                      max_iter=500, momentum=0.9,n_iter_no_change=10,nesterovs_momentum=True,power_t=0.5,random_state=None,shuffle=True,solver='adam',tol=0.0001,validation_fraction=0.1, verbose=False, warm_start=False)"
      ],
      "metadata": {
        "id": "DHls_068Djtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "mlp_model.fit(x_train, y_train_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGrHh3_6C1qQ",
        "outputId": "49ae6be3-e657-487f-ee3f-512b5c11d4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
              "              learning_rate='adaptive', max_iter=500)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "y_pred=mlp_model.predict(x_test)"
      ],
      "metadata": {
        "id": "pMOGljBDC32t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance evaluation"
      ],
      "metadata": {
        "id": "qq9CCC_jghzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance metrics: Accuracy\n",
        "accuracy=accuracy_score(y_true=y_test_encoded, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQo1R8XqC5Ws",
        "outputId": "427d440c-0f2a-457b-9770-d1808b5b9b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 88.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of DT classifier on training set: {:.2f}'\n",
        "     .format(mlp_model.score(x_train, y_train_encoded)))\n",
        "print('Accuracy of DT classifier on test set: {:.2f}'\n",
        "     .format(mlp_model.score(x_test, y_test_encoded)))\n",
        "print(\"----------------------------------\")\n",
        "print(classification_report(y_test_encoded, y_pred, target_names=['calm', 'disgust', 'fearful', 'happy']))\n",
        "print(\"----------------------------------\")\n",
        "cm   = confusion_matrix(y_test_encoded, y_pred, labels=[0, 1, 2, 3])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['calm', 'disgust', 'fearful', 'happy'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "uCKcRl-dgkqT",
        "outputId": "54ad4552-dc65-4b9c-9e14-12059612338f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of DT classifier on training set: 1.00\n",
            "Accuracy of DT classifier on test set: 0.89\n",
            "----------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       0.92      0.94      0.93       148\n",
            "     disgust       0.91      0.88      0.90       142\n",
            "     fearful       0.87      0.88      0.87       139\n",
            "       happy       0.84      0.84      0.84       147\n",
            "\n",
            "    accuracy                           0.89       576\n",
            "   macro avg       0.89      0.89      0.89       576\n",
            "weighted avg       0.89      0.89      0.89       576\n",
            "\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f3368139e10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1\n",
        "\n",
        "The first model consists of a Convolutional Neural Network that receives as input a 1-D vector with 189 elements (that is the dimension obtained from feature extraction). The model consists of 4 convolutional layers, which extract 128 filters each. The activation function used between layer is ReLU, and dropout of 0.2 is added at the end of each block."
      ],
      "metadata": {
        "id": "jJHJFftdZxRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_model_build():\n",
        "  input_layer = L.Input(shape=(189, 1))\n",
        "\n",
        "  cnn1 = L.Conv1D(256, (5))(input_layer)\n",
        "  batch_norm1 = L.BatchNormalization()(cnn1)\n",
        "  relu1 = L.ReLU()(batch_norm1)\n",
        "\n",
        "  cnn2 = L.Conv1D(128, (5))(relu1)\n",
        "  relu2 = L.ReLU()(cnn2)\n",
        "  dropout1 = L.Dropout(0.1)(relu2)\n",
        "  batch_norm2 = L.BatchNormalization()(dropout1)\n",
        "\n",
        "  max_pool1 = L.MaxPool1D(8)(batch_norm2)\n",
        "\n",
        "  conv3 = L.Conv1D(128, (5))(max_pool1)\n",
        "  relu3 = L.ReLU()(conv3)\n",
        "  conv4 = L.Conv1D(128, (5))(relu3)\n",
        "  relu4 = L.ReLU()(conv4)\n",
        "  conv5 = L.Conv1D(128, (5))(relu4)\n",
        "  batch_norm4 = L.BatchNormalization()(conv5)\n",
        "  relu5 = L.ReLU()(batch_norm4)\n",
        "  dropout2 = L.Dropout(0.2)(relu5)\n",
        "\n",
        "  conv6 = L.Conv1D(128, (5))(dropout2)\n",
        "  flatten = L.Flatten()(conv6)\n",
        "  dropout3 = L.Dropout(0.2)(flatten)\n",
        "\n",
        "  out_classes = 4\n",
        "  output_logits = L.Dense(out_classes)(dropout3)\n",
        "  batch_norm5 = L.BatchNormalization()(output_logits)\n",
        "  softmax = L.Softmax()(batch_norm5)\n",
        "  model = Model(inputs=[input_layer], outputs=[softmax])\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "NrohTxn6zgVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechModel:\n",
        "    def __init__(self, num_output_classes=4) -> None:\n",
        "        self.num_output_classes = num_output_classes\n",
        "\n",
        "    def getRAVDESS(self) -> Model:\n",
        "        \"\"\"Returns a tensorflow model that is according to specifications of the baseline CNN model in the paper.\"\"\"\n",
        "        input_layer = L.Input(shape=(189, 1))\n",
        "\n",
        "        cnn1 = L.Conv1D(256, (5))(input_layer)\n",
        "        batch_norm1 = L.BatchNormalization()(cnn1)\n",
        "        relu1 = L.ReLU()(batch_norm1)\n",
        "\n",
        "        cnn2 = L.Conv1D(128, (5))(relu1)\n",
        "        relu2 = L.ReLU()(cnn2)\n",
        "        dropout1 = L.Dropout(0.1)(relu2)\n",
        "        batch_norm2 = L.BatchNormalization()(dropout1)\n",
        "\n",
        "        max_pool1 = L.MaxPool1D(8)(batch_norm2)\n",
        "\n",
        "        conv3 = L.Conv1D(128, (5))(max_pool1)\n",
        "        relu3 = L.ReLU()(conv3)\n",
        "        conv4 = L.Conv1D(128, (5))(relu3)\n",
        "        relu4 = L.ReLU()(conv4)\n",
        "        conv5 = L.Conv1D(128, (5))(relu4)\n",
        "        batch_norm4 = L.BatchNormalization()(conv5)\n",
        "        relu5 = L.ReLU()(batch_norm4)\n",
        "        dropout2 = L.Dropout(0.2)(relu5)\n",
        "\n",
        "        conv6 = L.Conv1D(128, (5))(dropout2)\n",
        "        flatten = L.Flatten()(conv6)\n",
        "        dropout3 = L.Dropout(0.2)(flatten)\n",
        "\n",
        "        output_logits = L.Dense(self.num_output_classes)(dropout3)\n",
        "        batch_norm5 = L.BatchNormalization()(output_logits)\n",
        "        softmax = L.Softmax()(batch_norm5)\n",
        "        model = Model(inputs=[input_layer], outputs=[softmax])\n",
        "        optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "        model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "XY-p8VrJC7ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we filtered our dataset to only four different features (or emotions), we create the model with 4 output layers. The original batch size used is 64, and we train from an interval between 50 and 80 epochs."
      ],
      "metadata": {
        "id": "oDIy6KkWVJON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speech_model = SpeechModel(4)\n",
        "speech_model = speech_model.getRAVDESS()\n",
        "history = speech_model.fit(x_train, np.asarray(y_train_encoded), batch_size=64, epochs=80)"
      ],
      "metadata": {
        "id": "6l652NC0ZCV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e59980a-edb1-46d8-d01e-e1cfe24be9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "27/27 [==============================] - 14s 13ms/step - loss: 1.4880 - accuracy: 0.2894\n",
            "Epoch 2/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.4017 - accuracy: 0.3426\n",
            "Epoch 3/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.3260 - accuracy: 0.3663\n",
            "Epoch 4/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.2985 - accuracy: 0.3872\n",
            "Epoch 5/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.2450 - accuracy: 0.4225\n",
            "Epoch 6/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.2354 - accuracy: 0.4329\n",
            "Epoch 7/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.2142 - accuracy: 0.4300\n",
            "Epoch 8/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.2081 - accuracy: 0.4485\n",
            "Epoch 9/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1899 - accuracy: 0.4456\n",
            "Epoch 10/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1765 - accuracy: 0.4722\n",
            "Epoch 11/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1751 - accuracy: 0.4751\n",
            "Epoch 12/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1606 - accuracy: 0.4994\n",
            "Epoch 13/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1551 - accuracy: 0.4890\n",
            "Epoch 14/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1335 - accuracy: 0.5087\n",
            "Epoch 15/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.1323 - accuracy: 0.4902\n",
            "Epoch 16/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0993 - accuracy: 0.5394\n",
            "Epoch 17/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0929 - accuracy: 0.5208\n",
            "Epoch 18/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0923 - accuracy: 0.5301\n",
            "Epoch 19/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0722 - accuracy: 0.5428\n",
            "Epoch 20/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0713 - accuracy: 0.5324\n",
            "Epoch 21/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0553 - accuracy: 0.5498\n",
            "Epoch 22/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0470 - accuracy: 0.5666\n",
            "Epoch 23/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0439 - accuracy: 0.5602\n",
            "Epoch 24/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0278 - accuracy: 0.5804\n",
            "Epoch 25/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0202 - accuracy: 0.5723\n",
            "Epoch 26/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0269 - accuracy: 0.5747\n",
            "Epoch 27/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0172 - accuracy: 0.5897\n",
            "Epoch 28/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 1.0041 - accuracy: 0.5874\n",
            "Epoch 29/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9906 - accuracy: 0.6030\n",
            "Epoch 30/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9744 - accuracy: 0.6157\n",
            "Epoch 31/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9809 - accuracy: 0.6175\n",
            "Epoch 32/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9723 - accuracy: 0.6071\n",
            "Epoch 33/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9684 - accuracy: 0.6111\n",
            "Epoch 34/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9466 - accuracy: 0.6163\n",
            "Epoch 35/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9699 - accuracy: 0.5995\n",
            "Epoch 36/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9467 - accuracy: 0.6215\n",
            "Epoch 37/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9300 - accuracy: 0.6372\n",
            "Epoch 38/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9260 - accuracy: 0.6296\n",
            "Epoch 39/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9272 - accuracy: 0.6406\n",
            "Epoch 40/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9170 - accuracy: 0.6348\n",
            "Epoch 41/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9214 - accuracy: 0.6435\n",
            "Epoch 42/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8994 - accuracy: 0.6557\n",
            "Epoch 43/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.9107 - accuracy: 0.6372\n",
            "Epoch 44/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8975 - accuracy: 0.6591\n",
            "Epoch 45/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8786 - accuracy: 0.6678\n",
            "Epoch 46/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8780 - accuracy: 0.6817\n",
            "Epoch 47/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8689 - accuracy: 0.6869\n",
            "Epoch 48/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8684 - accuracy: 0.6736\n",
            "Epoch 49/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8692 - accuracy: 0.6782\n",
            "Epoch 50/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8529 - accuracy: 0.6840\n",
            "Epoch 51/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8667 - accuracy: 0.6829\n",
            "Epoch 52/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8759 - accuracy: 0.6690\n",
            "Epoch 53/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8457 - accuracy: 0.6939\n",
            "Epoch 54/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8413 - accuracy: 0.6944\n",
            "Epoch 55/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8603 - accuracy: 0.6811\n",
            "Epoch 56/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8293 - accuracy: 0.7031\n",
            "Epoch 57/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8366 - accuracy: 0.6991\n",
            "Epoch 58/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8122 - accuracy: 0.7072\n",
            "Epoch 59/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8233 - accuracy: 0.7089\n",
            "Epoch 60/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8112 - accuracy: 0.7222\n",
            "Epoch 61/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8237 - accuracy: 0.7054\n",
            "Epoch 62/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8053 - accuracy: 0.7118\n",
            "Epoch 63/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8143 - accuracy: 0.7205\n",
            "Epoch 64/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8075 - accuracy: 0.7118\n",
            "Epoch 65/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7992 - accuracy: 0.7095\n",
            "Epoch 66/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.7193\n",
            "Epoch 67/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7955 - accuracy: 0.7332\n",
            "Epoch 68/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7857 - accuracy: 0.7164\n",
            "Epoch 69/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7758 - accuracy: 0.7546\n",
            "Epoch 70/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7726 - accuracy: 0.7367\n",
            "Epoch 71/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7757 - accuracy: 0.7373\n",
            "Epoch 72/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7719 - accuracy: 0.7402\n",
            "Epoch 73/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7712 - accuracy: 0.7558\n",
            "Epoch 74/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7608 - accuracy: 0.7378\n",
            "Epoch 75/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7658 - accuracy: 0.7413\n",
            "Epoch 76/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7693 - accuracy: 0.7367\n",
            "Epoch 77/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7554 - accuracy: 0.7494\n",
            "Epoch 78/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7574 - accuracy: 0.7558\n",
            "Epoch 79/80\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.7463 - accuracy: 0.7523\n",
            "Epoch 80/80\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.7511 - accuracy: 0.7488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model"
      ],
      "metadata": {
        "id": "1i723_rFnoAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "y_pred=speech_model.predict(x_test)\n",
        "y_pred = tf.math.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "rkwcaBv6kCAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance evaluation"
      ],
      "metadata": {
        "id": "ViyX9GbWjzgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = speech_model.evaluate(x_train, np.asarray(y_train_encoded))\n",
        "accuracy_train = score[1]\n",
        "\n",
        "score = speech_model.evaluate(x_test, np.asarray(y_test_encoded))\n",
        "accuracy_test = score[1]\n",
        "\n",
        "print(f\"Accuracy in train data: {accuracy_train}\")\n",
        "print(f\"Accuracy in test data: {accuracy_test}\")"
      ],
      "metadata": {
        "id": "BGQ5kKDdZF-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a131d2-5a83-4c12-aa16-f40f65842fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54/54 [==============================] - 0s 3ms/step - loss: 0.7512 - accuracy: 0.7731\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9137 - accuracy: 0.6441\n",
            "Accuracy in train data: 0.7731481194496155\n",
            "Accuracy in test data: 0.6440972089767456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of speech model classifier on training set: {:.2f}'\n",
        "     .format(accuracy_train))\n",
        "print('Accuracy of speech model classifier on test set: {:.2f}'\n",
        "     .format(accuracy_test))\n",
        "print(\"----------------------------------\")\n",
        "print(classification_report(y_test_encoded, y_pred, target_names=['calm', 'disgust', 'fearful', 'happy']))\n",
        "print(\"----------------------------------\")\n",
        "cm   = confusion_matrix(y_test_encoded, y_pred, labels=[0, 1, 2, 3])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['calm', 'disgust', 'fearful', 'happy'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "dPoJd6D8j2fK",
        "outputId": "0609b7db-f50b-402c-a164-65827d25fa79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of speech model classifier on training set: 0.77\n",
            "Accuracy of speech model classifier on test set: 0.64\n",
            "----------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       0.92      0.53      0.68       148\n",
            "     disgust       0.48      0.85      0.62       142\n",
            "     fearful       0.84      0.55      0.66       139\n",
            "       happy       0.64      0.65      0.64       147\n",
            "\n",
            "    accuracy                           0.64       576\n",
            "   macro avg       0.72      0.64      0.65       576\n",
            "weighted avg       0.72      0.64      0.65       576\n",
            "\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f33501a9610>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "t43pfOl_aG0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVC MODEL"
      ],
      "metadata": {
        "id": "1GD9WA3zHTQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelsvc=SVC(kernel='rbf', C=660, gamma=0.001) "
      ],
      "metadata": {
        "id": "LxZxIvqcHNfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "modelsvc.fit(x_train,y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEBQH6MLIfkr",
        "outputId": "d3ed69e8-a61f-47e4-e6a8-ce9aadc67a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=660, gamma=0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "y_pred=modelsvc.predict(x_test)"
      ],
      "metadata": {
        "id": "CiNpm6gNInen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance metrics: Accuracy\n",
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfDp8F6vIs2y",
        "outputId": "942b8467-2c09-445d-c956-52790bc59b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----------------------------------\")\n",
        "print(classification_report(y_test, y_pred, target_names=['calm', 'disgust', 'fearful', 'happy']))\n",
        "print(\"----------------------------------\")\n",
        "cm   = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['calm', 'disgust', 'fearful', 'happy'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "8ISNnisgVe1n",
        "outputId": "2d82a94a-99a4-4f22-839c-4b3d73432fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       0.88      0.97      0.93       148\n",
            "     disgust       0.81      0.83      0.82       142\n",
            "     fearful       0.83      0.74      0.78       139\n",
            "       happy       0.79      0.78      0.78       147\n",
            "\n",
            "    accuracy                           0.83       576\n",
            "   macro avg       0.83      0.83      0.83       576\n",
            "weighted avg       0.83      0.83      0.83       576\n",
            "\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f3365477250>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9enbKCSDIe8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "oSJzcTVgaIFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Agumentation\n",
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
      ],
      "metadata": {
        "id": "45yAVq5QaIxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding( data, length ):\n",
        "    tf_array = tf.convert_to_tensor( data )\n",
        "    tf_zeros = np.zeros( length )\n",
        "    return np.array( tf.concat( [ tf_array, tf_zeros ], 0 ) )"
      ],
      "metadata": {
        "id": "xY96oQtpRuxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preprocessing"
      ],
      "metadata": {
        "id": "tyZn2F_can2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path     = '/content/gdrive/Shareddrives/CS4013/HW6/speech-emotion-recognition-ravdess-data/'\n",
        "Ravdess = path\n",
        "\n",
        "ravdess_directory_list = os.listdir(Ravdess)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "for dir in ravdess_directory_list:\n",
        "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
        "    actor = os.listdir(Ravdess + dir)\n",
        "    for file in actor:\n",
        "        part = file.split('.')[0]\n",
        "        part = part.split('-')\n",
        "        # third part in each file represents the emotion associated to that file.\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(Ravdess + dir + '/' + file)\n",
        "        \n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "path_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "# changing integers to actual emotions.\n",
        "path_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)"
      ],
      "metadata": {
        "id": "fQPTkze1QnPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotions types and number of samples in each class\n",
        "unique, counts = np.unique( path_df.Emotions, return_counts = True )\n",
        "dict( zip( unique, counts ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNFOYwWkQ8Or",
        "outputId": "980abd2a-7f4f-45ab-ceb6-60f6b48cae1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 192,\n",
              " 'calm': 192,\n",
              " 'disgust': 192,\n",
              " 'fear': 192,\n",
              " 'happy': 192,\n",
              " 'neutral': 96,\n",
              " 'sad': 192,\n",
              " 'surprise': 192}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load audio files\n",
        "dataset = []\n",
        "for emotion, path in tqdm( zip( path_df.Emotions, path_df.Path ), total = len( path_df.Emotions ) ):\n",
        "    data, sr = librosa.load( path )\n",
        "    dataset.append( [ emotion, data, sr] )\n",
        "dataset = np.array( dataset )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVl5g2lWRDGm",
        "outputId": "b332e122-65c5-43b0-80f9-075fbc435a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1440/1440 [20:27<00:00,  1.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions, audio_data, sampling_rate = dataset[ :,0 ], dataset[ :,1 ], np.unique( dataset[ :,2 ] )\n",
        "sampling_rate = sampling_rate[0]"
      ],
      "metadata": {
        "id": "ZV9V1s0iRD7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create DataFrame to filter audio by emotions in next steps\n",
        "df_data = pd.DataFrame( [ [ emotion, data ] for emotion, data in zip( emotions, audio_data ) ], columns = [ 'Emotions', 'Audio_Data' ] )"
      ],
      "metadata": {
        "id": "_Nxdzt5CRHF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the functions to agument the audio data. \n",
        "def augmented_data( df ):\n",
        "    data = []\n",
        "    for dat in tqdm( df.Audio_Data, total = len( df.Emotions.values ) ):\n",
        "        data.append( noise( dat )  )\n",
        "        data.append( stretch( dat) )\n",
        "        data.append( shift( dat)   )\n",
        "        data.append( pitch( dat, sampling_rate = sampling_rate) )\n",
        "    data = np.array( data )\n",
        "    data = np.array( [ [ df.Emotions.values[0], dat ] for dat in data ] )\n",
        "    return data "
      ],
      "metadata": {
        "id": "KobsCiOPRhA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seperate audio data into 4 different subsets. \n",
        "df_calm    = df_data.loc[ ( df_data.Emotions == 'calm')    ]\n",
        "df_disgust = df_data.loc[ ( df_data.Emotions == 'disgust') ]\n",
        "df_fear    = df_data.loc[ ( df_data.Emotions == 'fear')    ]\n",
        "df_happy   = df_data.loc[ ( df_data.Emotions == 'happy')   ]\n",
        "print( 'Shape of datasets: {}'.format( df_calm.shape ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9IooPCXRjPv",
        "outputId": "8f23433b-44f2-4fd5-b4e3-bd98ce1a065c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of datasets: (192, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agument the Audio Data\n",
        "calm    = augmented_data( df_calm )\n",
        "disgust = augmented_data( df_disgust )\n",
        "fear    = augmented_data( df_fear )\n",
        "happy   = augmented_data( df_happy )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22jWsOJpRmXH",
        "outputId": "cd8519c0-073a-49fd-b5a0-c6188899dda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 192/192 [00:32<00:00,  5.92it/s]\n",
            "100%|██████████| 192/192 [00:32<00:00,  5.85it/s]\n",
            "100%|██████████| 192/192 [00:31<00:00,  6.05it/s]\n",
            "100%|██████████| 192/192 [00:30<00:00,  6.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all audio data into a single DataSet\n",
        "augmented_data = calm\n",
        "augmented_data = np.append( augmented_data, disgust, axis = 0 )\n",
        "augmented_data = np.append( augmented_data, fear   , axis = 0 )\n",
        "augmented_data = np.append( augmented_data, happy  , axis = 0 )\n",
        "augmented_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK9NDrVARpI4",
        "outputId": "5236857b-b77b-4be3-da40-5f7ce9b812dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions, audio_data = augmented_data[:,0], augmented_data[:,1]\n",
        "\n",
        "#Obtain the maximum audio length\n",
        "shapes_audio = np.unique( np.array( [ data.shape for data in audio_data ] ) )\n",
        "max_shape = np.max( shapes_audio )\n",
        "print( \"Max shape of audio: {}\".format( max_shape ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvErDpNCRpzP",
        "outputId": "6cbaad88-5145-4edb-edf5-9adc8930163c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max shape of audio: 145309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape all audios with the same length\n",
        "audio_data = np.array( [ padding( data, max_shape - len( data ) ) for data in audio_data  ] )"
      ],
      "metadata": {
        "id": "4hFayCzjRwbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert 1D audio data into a 2D image data. By applying Fourier Transform it is obtained the spectrogram of each audio. \n",
        "spectrum_data = np.array( [ librosa.feature.melspectrogram( data, sr = sampling_rate ) for data in audio_data ]  )"
      ],
      "metadata": {
        "id": "_4UO-yVDRyuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize Spectogram for Neural Network\n",
        "normalize_spectrum_data = np.array( [  preprocessing.normalize( data ) for data in spectrum_data ] )\n",
        "normalize_spectrum_data = np.reshape( normalize_spectrum_data, ( len(normalize_spectrum_data), 128, 284, 1 ) )\n",
        "normalize_spectrum_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fBisTm3R5mY",
        "outputId": "f11e841c-befc-4574-e02f-7d257d37ff69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072, 128, 284, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode labels and count the number of classes in the DataSet\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_emotions = label_encoder.fit_transform( emotions )\n",
        "dictionary_emotions = { data : encoded_data for data, encoded_data in zip( emotions, encoded_emotions ) }\n",
        "no_classes = len( dictionary_emotions )\n",
        "print( 'Number of classes: {}'.format( no_classes ) )\n",
        "print( dictionary_emotions )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUHsrhuDR774",
        "outputId": "d6fc201c-496d-4b9e-9941-09f81cf0ad98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 4\n",
            "{'calm': 0, 'disgust': 1, 'fear': 2, 'happy': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split DataSet into train and test.\n",
        "x_train, x_test, y_train, y_test = train_test_split( normalize_spectrum_data, encoded_emotions, random_state=0, shuffle=True)\n",
        "print( 'Number of train samples {}. \\nNumber of test samples: {}'.format( len( x_train), len( x_test) ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk6__wsLSDyQ",
        "outputId": "d359e6b7-9edc-4bb2-f118-6103017d7d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples 2304. \n",
            "Number of test samples: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Neural Network Model"
      ],
      "metadata": {
        "id": "Aj9vpQP3iko_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Convolutional Neural Network\n",
        "def speech_classifier_model_3( no_classes=4 ):\n",
        "\n",
        "    input_layer = layers.Input( shape = ( 128, 284, 1 ) )\n",
        "\n",
        "    cnn_1        = layers.Conv2D( 64, (3,3), strides = (2,2), padding = 'same' )( input_layer )\n",
        "    max_pool_1   = layers.MaxPooling2D( pool_size = (2, 2), strides = (1, 1), padding='same' )( cnn_1 )\n",
        "    relu_1       = layers.LeakyReLU()( max_pool_1 )\n",
        "\n",
        "    cnn_2        = layers.Conv2D( 128, (3,3), strides = (2,2), padding = 'same' )( relu_1 )\n",
        "    max_pool_2   = layers.MaxPooling2D( pool_size = (2, 2), strides=(1, 1), padding='same' )( cnn_2 )\n",
        "    relu_2       = layers.LeakyReLU()( max_pool_2 )\n",
        "\n",
        "    cnn_3        = layers.Conv2D( 256, (3,3), strides = (2,2), padding = 'same' )( relu_2 )\n",
        "    max_pool_3   = layers.MaxPooling2D( pool_size = (2, 2), strides=(1, 1), padding='same' )( cnn_3 )\n",
        "    relu_3       = layers.LeakyReLU()( max_pool_3 )\n",
        "\n",
        "    flat         = layers.Flatten()( relu_3 )\n",
        "    dense_1      = layers.Dense( 50, activation = 'sigmoid' )( flat )\n",
        "    dense_2      = layers.Dense( no_classes, activation = 'softmax' )( dense_1 )\n",
        "\n",
        "    model        = Model( inputs = [ input_layer ], outputs = [ dense_2 ] )\n",
        "\n",
        "    loss         = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    optimizer    = tf.keras.optimizers.Adam( 2e-4 )\n",
        "\n",
        "    model.compile( optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n",
        "\n",
        "    return model "
      ],
      "metadata": {
        "id": "J8GIiOIySF8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_model_spectrum = speech_classifier_model_3( no_classes )\n",
        "speech_model_spectrum.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMZ_kK95SJfn",
        "outputId": "57092912-a91c-4826-884a-84b96f117c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 284, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 142, 64)       640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 142, 64)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 64, 142, 64)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 71, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 71, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 32, 71, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 36, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 36, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 36, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 147456)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                7372850   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,742,718\n",
            "Trainable params: 7,742,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = speech_model_spectrum.fit( x_train, y_train, batch_size = 64, epochs = 20, validation_data = ( x_test , y_test ) )"
      ],
      "metadata": {
        "id": "3Yr-1fVGSO9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ca51c4-1f2a-4e19-8169-b0303ea9cef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "36/36 [==============================] - 6s 111ms/step - loss: 1.3589 - accuracy: 0.3273 - val_loss: 1.2639 - val_accuracy: 0.4635\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 1.1798 - accuracy: 0.4831 - val_loss: 1.1369 - val_accuracy: 0.5195\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 1.0128 - accuracy: 0.5768 - val_loss: 0.9731 - val_accuracy: 0.5846\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.8570 - accuracy: 0.6580 - val_loss: 0.8996 - val_accuracy: 0.6146\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.7531 - accuracy: 0.7014 - val_loss: 0.8183 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.6282 - accuracy: 0.7687 - val_loss: 0.7797 - val_accuracy: 0.6823\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.5464 - accuracy: 0.7986 - val_loss: 0.7648 - val_accuracy: 0.7057\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 4s 103ms/step - loss: 0.4693 - accuracy: 0.8411 - val_loss: 0.6972 - val_accuracy: 0.7331\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 4s 104ms/step - loss: 0.3664 - accuracy: 0.8958 - val_loss: 0.6977 - val_accuracy: 0.7161\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 4s 102ms/step - loss: 0.3050 - accuracy: 0.9201 - val_loss: 0.6613 - val_accuracy: 0.7409\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.2476 - accuracy: 0.9453 - val_loss: 0.6463 - val_accuracy: 0.7474\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.1991 - accuracy: 0.9674 - val_loss: 0.6339 - val_accuracy: 0.7435\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 3s 93ms/step - loss: 0.1652 - accuracy: 0.9770 - val_loss: 0.6282 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.1337 - accuracy: 0.9865 - val_loss: 0.6128 - val_accuracy: 0.7591\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.1149 - accuracy: 0.9918 - val_loss: 0.6419 - val_accuracy: 0.7578\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0931 - accuracy: 0.9948 - val_loss: 0.6405 - val_accuracy: 0.7630\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0857 - accuracy: 0.9952 - val_loss: 0.6567 - val_accuracy: 0.7604\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0732 - accuracy: 0.9974 - val_loss: 0.6305 - val_accuracy: 0.7617\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0613 - accuracy: 0.9983 - val_loss: 0.6393 - val_accuracy: 0.7682\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 4s 100ms/step - loss: 0.0555 - accuracy: 0.9983 - val_loss: 0.6626 - val_accuracy: 0.7682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = speech_model_spectrum.evaluate(x_train, np.asarray(y_train))\n",
        "accuracy_train = score[1]\n",
        "\n",
        "score = speech_model_spectrum.evaluate(x_test, np.asarray(y_test))\n",
        "accuracy_test = score[1]\n",
        "\n",
        "print(f\"Accuracy in train data: {accuracy_train}\")\n",
        "print(f\"Accuracy in test data: {accuracy_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPnneEg2SQn0",
        "outputId": "1648a847-0b37-4772-87e7-985db81fbbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72/72 [==============================] - 2s 16ms/step - loss: 0.0515 - accuracy: 0.9987\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.6626 - accuracy: 0.7682\n",
            "Accuracy in train data: 0.9986979365348816\n",
            "Accuracy in test data: 0.7682291865348816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = speech_model_spectrum.predict( x_test )\n",
        "y_pred = np.array( [ np.argmax( pred ) for pred in y_pred ] ) \n",
        "\n",
        "print('Accuracy of speech model classifier on training set: {:.2f}'\n",
        "     .format(accuracy_train))\n",
        "print('Accuracy of speech model classifier on test set: {:.2f}'\n",
        "     .format(accuracy_test))\n",
        "print(\"----------------------------------\")\n",
        "print(classification_report(y_test, y_pred, target_names=['calm', 'disgust', 'fear', 'happy']))\n",
        "print(\"----------------------------------\")\n",
        "cm   = confusion_matrix(y_test, y_pred, labels= [0, 1, 2, 3] )\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['calm', 'disgust', 'fear', 'happy'])\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "9nesRl5NSSbT",
        "outputId": "ddd4796b-01a9-4ed3-b957-0ca13ad10eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of speech model classifier on training set: 1.00\n",
            "Accuracy of speech model classifier on test set: 0.77\n",
            "----------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       0.82      0.78      0.80       205\n",
            "     disgust       0.80      0.82      0.81       205\n",
            "        fear       0.69      0.82      0.75       166\n",
            "       happy       0.76      0.66      0.71       192\n",
            "\n",
            "    accuracy                           0.77       768\n",
            "   macro avg       0.77      0.77      0.77       768\n",
            "weighted avg       0.77      0.77      0.77       768\n",
            "\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f75a338a110>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare models\n",
        "models = []\n",
        "models.append(('CNN2', KerasClassifier(build_fn=speech_classifier_model_3, epochs=20, batch_size=64)))\n",
        "\n",
        "# evaluate each model in turnspeech_classifier_model_3\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "\tcv_results = model_selection.cross_val_score(model, normalize_spectrum_data, encoded_emotions, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu5_Ebjb0dwS",
        "outputId": "5f8f1d73-8a92-4696-cb08-e9883ba686bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "44/44 [==============================] - 15s 79ms/step - loss: 1.3986 - accuracy: 0.3057\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 1.2381 - accuracy: 0.4501\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 3s 76ms/step - loss: 1.0754 - accuracy: 0.5438\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.9350 - accuracy: 0.6241\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.7722 - accuracy: 0.7012\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 3s 77ms/step - loss: 0.6955 - accuracy: 0.7341\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.5952 - accuracy: 0.7851\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 3s 78ms/step - loss: 0.5039 - accuracy: 0.8216\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.4413 - accuracy: 0.8506\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.3784 - accuracy: 0.8828\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 3s 79ms/step - loss: 0.3496 - accuracy: 0.8929\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.2762 - accuracy: 0.9309\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.2234 - accuracy: 0.9515\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 0.1870 - accuracy: 0.9692\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1550 - accuracy: 0.9823\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1347 - accuracy: 0.9844\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1071 - accuracy: 0.9924\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0900 - accuracy: 0.9957\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0768 - accuracy: 0.9975\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0673 - accuracy: 0.9982\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 1.3331 - accuracy: 0.3531\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 1.1550 - accuracy: 0.4844\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.9644 - accuracy: 0.6078\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.8075 - accuracy: 0.6813\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.7032 - accuracy: 0.7381\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6005 - accuracy: 0.7894\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.5376 - accuracy: 0.8104\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.4607 - accuracy: 0.8495\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.4044 - accuracy: 0.8770\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.3615 - accuracy: 0.8940\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.2869 - accuracy: 0.9273\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.2572 - accuracy: 0.9367\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.2303 - accuracy: 0.9465\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1931 - accuracy: 0.9627\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1680 - accuracy: 0.9721\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1414 - accuracy: 0.9815\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1165 - accuracy: 0.9884\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.1002 - accuracy: 0.9920\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.0888 - accuracy: 0.9931\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.0775 - accuracy: 0.9946\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 1.3903 - accuracy: 0.3107\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.2054 - accuracy: 0.4637\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.0151 - accuracy: 0.5783\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.8444 - accuracy: 0.6684\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.7354 - accuracy: 0.7168\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6460 - accuracy: 0.7599\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.5412 - accuracy: 0.8210\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4452 - accuracy: 0.8651\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.3724 - accuracy: 0.8966\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.3189 - accuracy: 0.9244\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2599 - accuracy: 0.9450\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2263 - accuracy: 0.9559\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1845 - accuracy: 0.9769\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1475 - accuracy: 0.9837\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1268 - accuracy: 0.9888\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1134 - accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0981 - accuracy: 0.9928\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0889 - accuracy: 0.9949\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.0768 - accuracy: 0.9946\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0692 - accuracy: 0.9949\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 80ms/step - loss: 1.3600 - accuracy: 0.3335\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.1590 - accuracy: 0.4850\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.9876 - accuracy: 0.5765\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.8197 - accuracy: 0.6756\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.6965 - accuracy: 0.7385\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6026 - accuracy: 0.7776\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.5310 - accuracy: 0.8094\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4489 - accuracy: 0.8503\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.3904 - accuracy: 0.8752\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.3382 - accuracy: 0.9034\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2723 - accuracy: 0.9313\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2277 - accuracy: 0.9523\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1961 - accuracy: 0.9642\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1633 - accuracy: 0.9693\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1408 - accuracy: 0.9816\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1115 - accuracy: 0.9895\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1007 - accuracy: 0.9946\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0826 - accuracy: 0.9953\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0734 - accuracy: 0.9967\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0668 - accuracy: 0.9982\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.3250 - accuracy: 0.3675\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.0733 - accuracy: 0.5335\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.8862 - accuracy: 0.6401\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.7666 - accuracy: 0.6991\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.6666 - accuracy: 0.7385\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.5913 - accuracy: 0.7899\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.5049 - accuracy: 0.8231\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4261 - accuracy: 0.8597\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.3452 - accuracy: 0.8991\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.2980 - accuracy: 0.9204\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.2563 - accuracy: 0.9349\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.1995 - accuracy: 0.9624\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1750 - accuracy: 0.9703\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1477 - accuracy: 0.9794\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1174 - accuracy: 0.9870\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0988 - accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0841 - accuracy: 0.9949\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0743 - accuracy: 0.9960\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0649 - accuracy: 0.9975\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0577 - accuracy: 0.9986\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.3289 - accuracy: 0.3577\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.1263 - accuracy: 0.5002\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 0.9455 - accuracy: 0.6098\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.7989 - accuracy: 0.6832\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6693 - accuracy: 0.7566\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6180 - accuracy: 0.7642\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.5303 - accuracy: 0.8159\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4428 - accuracy: 0.8528\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.3735 - accuracy: 0.8868\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.3241 - accuracy: 0.9034\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2752 - accuracy: 0.9262\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2398 - accuracy: 0.9421\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.1989 - accuracy: 0.9627\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1789 - accuracy: 0.9649\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1565 - accuracy: 0.9754\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1229 - accuracy: 0.9884\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1012 - accuracy: 0.9917\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0871 - accuracy: 0.9957\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0752 - accuracy: 0.9971\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0687 - accuracy: 0.9975\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.3150 - accuracy: 0.3675\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.0542 - accuracy: 0.5508\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.8496 - accuracy: 0.6622\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.7131 - accuracy: 0.7168\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.5940 - accuracy: 0.7819\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.5127 - accuracy: 0.8235\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4170 - accuracy: 0.8633\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.3456 - accuracy: 0.8944\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.2824 - accuracy: 0.9219\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.2399 - accuracy: 0.9421\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.1976 - accuracy: 0.9580\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.1596 - accuracy: 0.9732\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.1335 - accuracy: 0.9801\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1070 - accuracy: 0.9910\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0895 - accuracy: 0.9942\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0736 - accuracy: 0.9971\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0631 - accuracy: 0.9978\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0557 - accuracy: 0.9982\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0506 - accuracy: 0.9986\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0453 - accuracy: 0.9982\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.3339 - accuracy: 0.3573\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 81ms/step - loss: 1.1336 - accuracy: 0.4976\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.9524 - accuracy: 0.6007\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.8081 - accuracy: 0.6709\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.7126 - accuracy: 0.7262\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.6449 - accuracy: 0.7562\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.5398 - accuracy: 0.8134\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.4697 - accuracy: 0.8470\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.4085 - accuracy: 0.8640\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 85ms/step - loss: 0.3436 - accuracy: 0.9042\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2921 - accuracy: 0.9248\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2417 - accuracy: 0.9537\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 84ms/step - loss: 0.2060 - accuracy: 0.9627\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1687 - accuracy: 0.9743\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1489 - accuracy: 0.9834\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1187 - accuracy: 0.9884\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.1034 - accuracy: 0.9910\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0979 - accuracy: 0.9910\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0805 - accuracy: 0.9946\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.0715 - accuracy: 0.9953\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.3865 - accuracy: 0.3049\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.2448 - accuracy: 0.4286\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.0540 - accuracy: 0.5552\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.8697 - accuracy: 0.6532\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.7473 - accuracy: 0.7172\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.6535 - accuracy: 0.7537\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.5694 - accuracy: 0.7942\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.4919 - accuracy: 0.8365\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.4583 - accuracy: 0.8409\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.3691 - accuracy: 0.8929\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.3173 - accuracy: 0.9139\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2778 - accuracy: 0.9251\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2211 - accuracy: 0.9523\n",
            "Epoch 14/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2004 - accuracy: 0.9584\n",
            "Epoch 15/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1614 - accuracy: 0.9772\n",
            "Epoch 16/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1363 - accuracy: 0.9837\n",
            "Epoch 17/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.1151 - accuracy: 0.9895\n",
            "Epoch 18/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0970 - accuracy: 0.9942\n",
            "Epoch 19/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0847 - accuracy: 0.9960\n",
            "Epoch 20/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.0730 - accuracy: 0.9964\n",
            "Epoch 1/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.3489 - accuracy: 0.3320\n",
            "Epoch 2/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 1.1482 - accuracy: 0.4886\n",
            "Epoch 3/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.9514 - accuracy: 0.6083\n",
            "Epoch 4/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.8157 - accuracy: 0.6665\n",
            "Epoch 5/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.7169 - accuracy: 0.7049\n",
            "Epoch 6/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.6043 - accuracy: 0.7783\n",
            "Epoch 7/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.5290 - accuracy: 0.8080\n",
            "Epoch 8/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.4382 - accuracy: 0.8546\n",
            "Epoch 9/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.3673 - accuracy: 0.8817\n",
            "Epoch 10/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.3263 - accuracy: 0.9038\n",
            "Epoch 11/20\n",
            "44/44 [==============================] - 4s 82ms/step - loss: 0.2659 - accuracy: 0.9269\n",
            "Epoch 12/20\n",
            "44/44 [==============================] - 4s 83ms/step - loss: 0.2405 - accuracy: 0.9356\n",
            "Epoch 13/20\n",
            "44/44 [==============================] - 4s 86ms/step - loss: 0.1823 - accuracy: 0.9617\n",
            "Epoch 14/20\n",
            "28/44 [==================>...........] - ETA: 1s - loss: 0.1634 - accuracy: 0.9721"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance comparison"
      ],
      "metadata": {
        "id": "6Dgol4ZJmWgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "n88zGy_pnEdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_le = LabelEncoder()\n",
        "\n",
        "Y_encoded      = y_le.fit_transform(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-5RPBkFtvzS",
        "outputId": "3d217303-60c8-479d-c855-dcb975d53565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 ... 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare models\n",
        "models = []\n",
        "models.append(('MLP', mlp_model))\n",
        "models.append(('CNN', KerasClassifier(build_fn=speech_model_build, epochs=50, batch_size=64)))\n",
        "#models.append(('CNN2', KerasClassifier(build_fn=, epochs=50, batch_size=64)))\n",
        "models.append(('SVM', modelsvc))\n",
        "# evaluate each model in turnspeech_classifier_model_3\n",
        "#results = []\n",
        "#names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, Y_encoded, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7b6g2jTmYhQ",
        "outputId": "17bcaf31-7215-46f9-c01f-c888c75c2a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP: 0.902321 (0.021130)\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 4s 27ms/step - loss: 1.5433 - accuracy: 0.2576\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.4122 - accuracy: 0.3237\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3645 - accuracy: 0.3666\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3047 - accuracy: 0.3825\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2581 - accuracy: 0.4221\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2416 - accuracy: 0.4182\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2065 - accuracy: 0.4481\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1842 - accuracy: 0.4631\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1671 - accuracy: 0.4761\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1470 - accuracy: 0.5031\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1461 - accuracy: 0.4949\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1317 - accuracy: 0.5142\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1159 - accuracy: 0.5109\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1111 - accuracy: 0.5248\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0921 - accuracy: 0.5364\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0882 - accuracy: 0.5480\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0835 - accuracy: 0.5432\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0503 - accuracy: 0.5567\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0586 - accuracy: 0.5470\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0436 - accuracy: 0.5740\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0253 - accuracy: 0.5712\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0186 - accuracy: 0.5750\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0088 - accuracy: 0.5982\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9881 - accuracy: 0.6117\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9993 - accuracy: 0.5943\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9978 - accuracy: 0.6088\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9819 - accuracy: 0.6102\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9709 - accuracy: 0.6233\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9580 - accuracy: 0.6295\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9669 - accuracy: 0.6136\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9565 - accuracy: 0.6257\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9315 - accuracy: 0.6242\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9212 - accuracy: 0.6416\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 0.9247 - accuracy: 0.6343\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 0.9278 - accuracy: 0.6348\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9045 - accuracy: 0.6585\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9087 - accuracy: 0.6479\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9053 - accuracy: 0.6551\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8886 - accuracy: 0.6691\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8750 - accuracy: 0.6792\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8769 - accuracy: 0.6778\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8719 - accuracy: 0.6778\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8732 - accuracy: 0.6753\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8781 - accuracy: 0.6753\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8625 - accuracy: 0.6869\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8599 - accuracy: 0.6874\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8603 - accuracy: 0.6908\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8410 - accuracy: 0.6927\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8387 - accuracy: 0.7000\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8269 - accuracy: 0.7130\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 13ms/step - loss: 1.5286 - accuracy: 0.2634\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3953 - accuracy: 0.3329\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3282 - accuracy: 0.3748\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2646 - accuracy: 0.4096\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2488 - accuracy: 0.4211\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2369 - accuracy: 0.4327\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2272 - accuracy: 0.4317\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2208 - accuracy: 0.4452\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1996 - accuracy: 0.4631\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1794 - accuracy: 0.4718\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1769 - accuracy: 0.4771\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1641 - accuracy: 0.4781\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1407 - accuracy: 0.5147\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1399 - accuracy: 0.5080\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1208 - accuracy: 0.5162\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1113 - accuracy: 0.5186\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1131 - accuracy: 0.5253\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0962 - accuracy: 0.5258\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0863 - accuracy: 0.5330\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0745 - accuracy: 0.5456\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0639 - accuracy: 0.5644\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0492 - accuracy: 0.5687\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0375 - accuracy: 0.5687\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0233 - accuracy: 0.5745\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0152 - accuracy: 0.5953\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0173 - accuracy: 0.5803\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0114 - accuracy: 0.5977\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0143 - accuracy: 0.5880\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9800 - accuracy: 0.6083\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9590 - accuracy: 0.6170\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9562 - accuracy: 0.6117\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9579 - accuracy: 0.6281\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9436 - accuracy: 0.6199\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9478 - accuracy: 0.6175\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9591 - accuracy: 0.6073\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9361 - accuracy: 0.6387\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9248 - accuracy: 0.6440\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9193 - accuracy: 0.6430\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9190 - accuracy: 0.6358\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9005 - accuracy: 0.6565\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8988 - accuracy: 0.6546\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8922 - accuracy: 0.6474\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8975 - accuracy: 0.6503\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8748 - accuracy: 0.6647\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8712 - accuracy: 0.6821\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8669 - accuracy: 0.6816\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8569 - accuracy: 0.6845\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8671 - accuracy: 0.6662\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8579 - accuracy: 0.6807\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8438 - accuracy: 0.6807\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 15ms/step - loss: 1.5005 - accuracy: 0.2745\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3843 - accuracy: 0.3386\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.3312 - accuracy: 0.3526\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3025 - accuracy: 0.3690\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2672 - accuracy: 0.4009\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2487 - accuracy: 0.4062\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2348 - accuracy: 0.4202\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2177 - accuracy: 0.4424\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1947 - accuracy: 0.4534\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1922 - accuracy: 0.4491\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1769 - accuracy: 0.4684\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1560 - accuracy: 0.4723\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1535 - accuracy: 0.4771\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1362 - accuracy: 0.4998\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1136 - accuracy: 0.5210\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1096 - accuracy: 0.5017\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0929 - accuracy: 0.5364\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0816 - accuracy: 0.5335\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0563 - accuracy: 0.5499\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0580 - accuracy: 0.5533\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0265 - accuracy: 0.5620\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0451 - accuracy: 0.5610\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0205 - accuracy: 0.5832\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9981 - accuracy: 0.5789\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0161 - accuracy: 0.5789\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9891 - accuracy: 0.5880\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9879 - accuracy: 0.5890\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9782 - accuracy: 0.6073\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9607 - accuracy: 0.6218\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9547 - accuracy: 0.6179\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9514 - accuracy: 0.6271\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9509 - accuracy: 0.6247\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9455 - accuracy: 0.6237\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9309 - accuracy: 0.6257\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9283 - accuracy: 0.6281\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9065 - accuracy: 0.6450\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9036 - accuracy: 0.6532\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9085 - accuracy: 0.6532\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8899 - accuracy: 0.6647\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8724 - accuracy: 0.6691\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8677 - accuracy: 0.6850\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8596 - accuracy: 0.6864\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8737 - accuracy: 0.6657\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8601 - accuracy: 0.6782\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8402 - accuracy: 0.6951\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8455 - accuracy: 0.6913\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8521 - accuracy: 0.6956\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8269 - accuracy: 0.7091\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8264 - accuracy: 0.7033\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8205 - accuracy: 0.7033\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 15ms/step - loss: 1.6173 - accuracy: 0.2547\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.4983 - accuracy: 0.3179\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3893 - accuracy: 0.3439\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3285 - accuracy: 0.3739\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2948 - accuracy: 0.4202\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2669 - accuracy: 0.4235\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2719 - accuracy: 0.4293\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2364 - accuracy: 0.4231\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2216 - accuracy: 0.4457\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1959 - accuracy: 0.4616\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1863 - accuracy: 0.4718\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1852 - accuracy: 0.4689\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1613 - accuracy: 0.4853\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1457 - accuracy: 0.4993\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1329 - accuracy: 0.5036\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1206 - accuracy: 0.5055\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1123 - accuracy: 0.5099\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0921 - accuracy: 0.5248\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1048 - accuracy: 0.5350\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0733 - accuracy: 0.5596\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0639 - accuracy: 0.5523\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0529 - accuracy: 0.5543\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0402 - accuracy: 0.5750\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0317 - accuracy: 0.5774\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0317 - accuracy: 0.5683\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0164 - accuracy: 0.5745\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0144 - accuracy: 0.5794\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0037 - accuracy: 0.5962\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9914 - accuracy: 0.5929\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9982 - accuracy: 0.5953\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9695 - accuracy: 0.6097\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9756 - accuracy: 0.6107\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9684 - accuracy: 0.6122\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9685 - accuracy: 0.6146\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9496 - accuracy: 0.6151\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9430 - accuracy: 0.6358\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9385 - accuracy: 0.6310\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9361 - accuracy: 0.6295\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9251 - accuracy: 0.6377\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9220 - accuracy: 0.6290\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9052 - accuracy: 0.6604\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9107 - accuracy: 0.6570\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 1s 16ms/step - loss: 0.8926 - accuracy: 0.6570\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 1s 15ms/step - loss: 0.8866 - accuracy: 0.6705\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 1s 17ms/step - loss: 0.8741 - accuracy: 0.6614\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 1s 16ms/step - loss: 0.8933 - accuracy: 0.6657\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 0.8789 - accuracy: 0.6729\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8645 - accuracy: 0.6739\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8605 - accuracy: 0.6811\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8531 - accuracy: 0.6739\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 26ms/step - loss: 1.4325 - accuracy: 0.3110\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3688 - accuracy: 0.3554\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3165 - accuracy: 0.3660\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3024 - accuracy: 0.3987\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2647 - accuracy: 0.4041\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2472 - accuracy: 0.4171\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2433 - accuracy: 0.4291\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2084 - accuracy: 0.4677\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1851 - accuracy: 0.4658\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1826 - accuracy: 0.4638\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1737 - accuracy: 0.4802\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1626 - accuracy: 0.4923\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1330 - accuracy: 0.5039\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1290 - accuracy: 0.5106\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1191 - accuracy: 0.5174\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1112 - accuracy: 0.5275\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0935 - accuracy: 0.5492\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0725 - accuracy: 0.5559\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0828 - accuracy: 0.5395\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0451 - accuracy: 0.5559\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0588 - accuracy: 0.5492\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0444 - accuracy: 0.5579\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0220 - accuracy: 0.5757\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0284 - accuracy: 0.5820\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0086 - accuracy: 0.5878\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0081 - accuracy: 0.5959\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9898 - accuracy: 0.5926\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9864 - accuracy: 0.6114\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9739 - accuracy: 0.6075\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9715 - accuracy: 0.6128\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9638 - accuracy: 0.6085\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9551 - accuracy: 0.6268\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9434 - accuracy: 0.6311\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9504 - accuracy: 0.6230\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9299 - accuracy: 0.6336\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9305 - accuracy: 0.6345\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9284 - accuracy: 0.6292\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9115 - accuracy: 0.6524\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9153 - accuracy: 0.6403\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9057 - accuracy: 0.6427\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8852 - accuracy: 0.6644\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8860 - accuracy: 0.6639\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8765 - accuracy: 0.6678\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8860 - accuracy: 0.6707\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8613 - accuracy: 0.6832\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8671 - accuracy: 0.6871\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8583 - accuracy: 0.6808\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8706 - accuracy: 0.6760\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8444 - accuracy: 0.6914\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8398 - accuracy: 0.6924\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 15ms/step - loss: 1.4469 - accuracy: 0.2782\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3753 - accuracy: 0.3428\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3067 - accuracy: 0.3809\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2972 - accuracy: 0.3833\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2608 - accuracy: 0.4098\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2520 - accuracy: 0.4176\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2186 - accuracy: 0.4489\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2229 - accuracy: 0.4378\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1932 - accuracy: 0.4595\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1863 - accuracy: 0.4672\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1760 - accuracy: 0.4716\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1612 - accuracy: 0.4841\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1616 - accuracy: 0.4865\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1451 - accuracy: 0.5005\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1182 - accuracy: 0.5207\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1150 - accuracy: 0.5270\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1151 - accuracy: 0.5169\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1050 - accuracy: 0.5212\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0787 - accuracy: 0.5473\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0816 - accuracy: 0.5448\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0778 - accuracy: 0.5448\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0603 - accuracy: 0.5468\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0588 - accuracy: 0.5608\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0402 - accuracy: 0.5689\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0188 - accuracy: 0.5839\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0261 - accuracy: 0.5776\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0152 - accuracy: 0.6022\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9913 - accuracy: 0.6066\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9866 - accuracy: 0.5974\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9927 - accuracy: 0.6148\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9849 - accuracy: 0.6157\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9747 - accuracy: 0.5974\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9482 - accuracy: 0.6278\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9432 - accuracy: 0.6307\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9339 - accuracy: 0.6360\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9359 - accuracy: 0.6345\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9270 - accuracy: 0.6538\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9208 - accuracy: 0.6466\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9228 - accuracy: 0.6418\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8982 - accuracy: 0.6586\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9025 - accuracy: 0.6606\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8965 - accuracy: 0.6736\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8875 - accuracy: 0.6745\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8979 - accuracy: 0.6620\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8824 - accuracy: 0.6635\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8808 - accuracy: 0.6625\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8674 - accuracy: 0.6731\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8623 - accuracy: 0.6847\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8743 - accuracy: 0.6808\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8446 - accuracy: 0.6948\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 14ms/step - loss: 1.5633 - accuracy: 0.2594\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.4560 - accuracy: 0.3023\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3541 - accuracy: 0.3684\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3034 - accuracy: 0.3939\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2707 - accuracy: 0.4267\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2493 - accuracy: 0.4127\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2286 - accuracy: 0.4542\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1962 - accuracy: 0.4793\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1883 - accuracy: 0.4740\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1660 - accuracy: 0.4841\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1481 - accuracy: 0.5019\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1352 - accuracy: 0.4990\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1332 - accuracy: 0.4966\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1234 - accuracy: 0.5284\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0919 - accuracy: 0.5318\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0907 - accuracy: 0.5289\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0924 - accuracy: 0.5260\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0791 - accuracy: 0.5376\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0558 - accuracy: 0.5473\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0592 - accuracy: 0.5569\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0388 - accuracy: 0.5685\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0436 - accuracy: 0.5670\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0289 - accuracy: 0.5728\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0256 - accuracy: 0.5762\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0228 - accuracy: 0.5694\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0063 - accuracy: 0.5916\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9865 - accuracy: 0.6037\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9800 - accuracy: 0.5993\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9723 - accuracy: 0.6090\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9693 - accuracy: 0.6041\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9558 - accuracy: 0.6167\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9516 - accuracy: 0.6307\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9371 - accuracy: 0.6297\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9334 - accuracy: 0.6345\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9443 - accuracy: 0.6230\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9305 - accuracy: 0.6321\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9220 - accuracy: 0.6321\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9141 - accuracy: 0.6500\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9001 - accuracy: 0.6591\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8978 - accuracy: 0.6543\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8907 - accuracy: 0.6635\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8870 - accuracy: 0.6668\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8851 - accuracy: 0.6562\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8653 - accuracy: 0.6712\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8725 - accuracy: 0.6745\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8660 - accuracy: 0.6847\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8487 - accuracy: 0.6818\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8546 - accuracy: 0.6818\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8372 - accuracy: 0.6929\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8418 - accuracy: 0.6948\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 16ms/step - loss: 1.5139 - accuracy: 0.2874\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3990 - accuracy: 0.3332\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3174 - accuracy: 0.3722\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3111 - accuracy: 0.3660\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2676 - accuracy: 0.3978\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2554 - accuracy: 0.4132\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2342 - accuracy: 0.4455\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2046 - accuracy: 0.4662\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1951 - accuracy: 0.4614\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1834 - accuracy: 0.4764\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1665 - accuracy: 0.4932\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1711 - accuracy: 0.4778\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1563 - accuracy: 0.4913\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1401 - accuracy: 0.4986\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1260 - accuracy: 0.5111\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1195 - accuracy: 0.5164\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1099 - accuracy: 0.5217\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1054 - accuracy: 0.5140\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0779 - accuracy: 0.5429\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0810 - accuracy: 0.5497\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0496 - accuracy: 0.5564\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0568 - accuracy: 0.5689\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0381 - accuracy: 0.5646\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0278 - accuracy: 0.5738\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0264 - accuracy: 0.5747\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0190 - accuracy: 0.5791\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0038 - accuracy: 0.6008\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0133 - accuracy: 0.5810\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9954 - accuracy: 0.5974\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9828 - accuracy: 0.6051\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9798 - accuracy: 0.6090\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9817 - accuracy: 0.6070\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9534 - accuracy: 0.6167\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9507 - accuracy: 0.6273\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9489 - accuracy: 0.6316\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9406 - accuracy: 0.6456\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9315 - accuracy: 0.6403\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9293 - accuracy: 0.6524\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9141 - accuracy: 0.6500\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9103 - accuracy: 0.6586\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9081 - accuracy: 0.6601\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8870 - accuracy: 0.6683\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8687 - accuracy: 0.6885\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8765 - accuracy: 0.6779\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8780 - accuracy: 0.6745\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8599 - accuracy: 0.6750\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8625 - accuracy: 0.6851\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8635 - accuracy: 0.6842\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8588 - accuracy: 0.6861\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8548 - accuracy: 0.6991\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 15ms/step - loss: 1.5083 - accuracy: 0.3139\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.3761 - accuracy: 0.3578\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3187 - accuracy: 0.3674\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2821 - accuracy: 0.3910\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2669 - accuracy: 0.3891\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2414 - accuracy: 0.4238\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2159 - accuracy: 0.4537\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1810 - accuracy: 0.4566\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 1.1905 - accuracy: 0.4523\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1711 - accuracy: 0.4749\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 1.1653 - accuracy: 0.4826\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 1.1350 - accuracy: 0.5058\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1195 - accuracy: 0.5058\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1123 - accuracy: 0.5092\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1135 - accuracy: 0.5140\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0897 - accuracy: 0.5352\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0750 - accuracy: 0.5371\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0921 - accuracy: 0.5352\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0785 - accuracy: 0.5453\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0631 - accuracy: 0.5342\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0617 - accuracy: 0.5468\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0426 - accuracy: 0.5477\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0218 - accuracy: 0.5743\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0272 - accuracy: 0.5535\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0250 - accuracy: 0.5781\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0022 - accuracy: 0.5887\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9996 - accuracy: 0.5824\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9716 - accuracy: 0.5993\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9617 - accuracy: 0.6119\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9560 - accuracy: 0.6186\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9678 - accuracy: 0.6066\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9599 - accuracy: 0.6070\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9506 - accuracy: 0.6128\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9498 - accuracy: 0.6181\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9431 - accuracy: 0.6095\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9314 - accuracy: 0.6311\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9140 - accuracy: 0.6461\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9129 - accuracy: 0.6398\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9110 - accuracy: 0.6442\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9069 - accuracy: 0.6533\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8825 - accuracy: 0.6557\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8853 - accuracy: 0.6789\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8816 - accuracy: 0.6639\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8743 - accuracy: 0.6697\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8666 - accuracy: 0.6663\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8615 - accuracy: 0.6823\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8566 - accuracy: 0.6847\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8455 - accuracy: 0.6885\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8539 - accuracy: 0.6943\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8469 - accuracy: 0.6962\n",
            "Epoch 1/50\n",
            "33/33 [==============================] - 2s 14ms/step - loss: 1.6265 - accuracy: 0.2801\n",
            "Epoch 2/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.5008 - accuracy: 0.3312\n",
            "Epoch 3/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.3946 - accuracy: 0.3804\n",
            "Epoch 4/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.3177 - accuracy: 0.3930\n",
            "Epoch 5/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.2702 - accuracy: 0.4122\n",
            "Epoch 6/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2510 - accuracy: 0.4296\n",
            "Epoch 7/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2360 - accuracy: 0.4243\n",
            "Epoch 8/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.2267 - accuracy: 0.4455\n",
            "Epoch 9/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1907 - accuracy: 0.4677\n",
            "Epoch 10/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1998 - accuracy: 0.4542\n",
            "Epoch 11/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1801 - accuracy: 0.4759\n",
            "Epoch 12/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1698 - accuracy: 0.4797\n",
            "Epoch 13/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1376 - accuracy: 0.4952\n",
            "Epoch 14/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1472 - accuracy: 0.4908\n",
            "Epoch 15/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1302 - accuracy: 0.4966\n",
            "Epoch 16/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1040 - accuracy: 0.5188\n",
            "Epoch 17/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.1050 - accuracy: 0.5169\n",
            "Epoch 18/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0792 - accuracy: 0.5482\n",
            "Epoch 19/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.1086 - accuracy: 0.5227\n",
            "Epoch 20/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0747 - accuracy: 0.5487\n",
            "Epoch 21/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0730 - accuracy: 0.5477\n",
            "Epoch 22/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0484 - accuracy: 0.5588\n",
            "Epoch 23/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0312 - accuracy: 0.5800\n",
            "Epoch 24/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0374 - accuracy: 0.5598\n",
            "Epoch 25/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0292 - accuracy: 0.5733\n",
            "Epoch 26/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0247 - accuracy: 0.5670\n",
            "Epoch 27/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 1.0133 - accuracy: 0.5844\n",
            "Epoch 28/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9994 - accuracy: 0.5873\n",
            "Epoch 29/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 1.0042 - accuracy: 0.5906\n",
            "Epoch 30/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9832 - accuracy: 0.6070\n",
            "Epoch 31/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.9862 - accuracy: 0.6032\n",
            "Epoch 32/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9785 - accuracy: 0.5974\n",
            "Epoch 33/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9694 - accuracy: 0.6162\n",
            "Epoch 34/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9524 - accuracy: 0.6389\n",
            "Epoch 35/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9564 - accuracy: 0.6066\n",
            "Epoch 36/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9469 - accuracy: 0.6148\n",
            "Epoch 37/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9339 - accuracy: 0.6336\n",
            "Epoch 38/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9372 - accuracy: 0.6292\n",
            "Epoch 39/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9165 - accuracy: 0.6365\n",
            "Epoch 40/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9292 - accuracy: 0.6311\n",
            "Epoch 41/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9093 - accuracy: 0.6408\n",
            "Epoch 42/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.9092 - accuracy: 0.6528\n",
            "Epoch 43/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8927 - accuracy: 0.6649\n",
            "Epoch 44/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8900 - accuracy: 0.6471\n",
            "Epoch 45/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8769 - accuracy: 0.6779\n",
            "Epoch 46/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8826 - accuracy: 0.6630\n",
            "Epoch 47/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8734 - accuracy: 0.6712\n",
            "Epoch 48/50\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.8615 - accuracy: 0.6774\n",
            "Epoch 49/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8739 - accuracy: 0.6678\n",
            "Epoch 50/50\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.8523 - accuracy: 0.6760\n",
            "CNN: 0.605462 (0.033026)\n",
            "SVM: 0.855901 (0.025851)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Accuracy comparison for a 10-fold cross validation')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YkT5UX8ynHiB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}